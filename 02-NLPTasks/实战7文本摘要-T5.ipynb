{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 基于T5的文本摘要"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Looking in indexes: https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple\n",
         "Requirement already satisfied: rouge-chinese in /node6_1/tanshuai/.conda/envs/abc/lib/python3.9/site-packages (1.0.3)\n",
         "Requirement already satisfied: six in /node6_1/tanshuai/.conda/envs/abc/lib/python3.9/site-packages (from rouge-chinese) (1.16.0)\n"
        ]
       }
      ],
      "source": [
       "! pip install rouge-chinese"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Step1 导入相关包"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
       "import os\n",
       "\n",
       "# 设置可见的 GPU\n",
       "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4,5,7\"\n",
       "\n",
       "import torch\n",
       "from datasets import  Dataset\n",
       "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Step2 加载数据集"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
       {
        "data": {
         "text/plain": [
          "Dataset({\n",
          "    features: ['title', 'content'],\n",
          "    num_rows: 5000\n",
          "})"
         ]
        },
        "execution_count": 3,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "ds = Dataset.load_from_disk(\"nlpcc_2017\")\n",
       "ds"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
       {
        "data": {
         "text/plain": [
          "DatasetDict({\n",
          "    train: Dataset({\n",
          "        features: ['title', 'content'],\n",
          "        num_rows: 4800\n",
          "    })\n",
          "    test: Dataset({\n",
          "        features: ['title', 'content'],\n",
          "        num_rows: 200\n",
          "    })\n",
          "})"
         ]
        },
        "execution_count": 4,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "ds = ds.train_test_split(200, seed=42)\n",
       "ds"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
       {
        "data": {
         "text/plain": [
          "{'title': '郴州市发布雷电橙色预警:过去2小时北湖区、苏仙区、郴州市区、桂阳县、宜章县、嘉禾县、资兴市、桂东县、汝城县已经受...',\n",
          " 'content': '发布日期:2015-03-3007:55:33郴州市气象台3月30日7时52分发布雷电橙色预警信号:过去2小时北湖区、苏仙区、郴州市区、桂阳县、宜章县、嘉禾县、资兴市、桂东县、汝城县已经受雷电活动影响,并将持续,出现雷电灾害事故的可能性比较大,请注意防范。图例标准防御指南2小时内发生雷电活动的可能性很大,或者已经受雷电活动影响,且可能持续,出现雷电灾害事故的可能性比较大。1、政府及相关部门按照职责落实防雷应急措施;2、人员应当留在室内,并关好门窗;3、户外人员应当躲入有防雷设施的建筑物或者汽车内;4、切断危险电源,不要在树下、电杆下、塔吊下避雨;5、在空旷场地不要打伞,不要把农具、羽毛球拍、高尔夫球杆等扛在肩上。'}"
         ]
        },
        "execution_count": 5,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "ds[\"train\"][0]"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Step3 数据集处理"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
       {
        "name": "stderr",
        "output_type": "stream",
        "text": [
         "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
        ]
       }
      ],
      "source": [
       "tokenizer = AutoTokenizer.from_pretrained(\"Langboat/mengzi-t5-base\")\n",
       "# tokenizer"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
       "def process_function(examples):\n",
       "    contents = [\"摘要生成：\\n\" + e for e in examples[\"content\"]]\n",
       "    inputs = tokenizer(contents, max_length=384, truncation=True)\n",
       "    labels = tokenizer(text_target=examples[\"title\"], max_length=64, truncation=True)\n",
       "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
       "    return inputs"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
       {
        "data": {
         "application/vnd.jupyter.widget-view+json": {
          "model_id": "f4b300d46e9f4493a68df192d54a73bf",
          "version_major": 2,
          "version_minor": 0
         },
         "text/plain": [
          "Map:   0%|          | 0/4800 [00:00<?, ? examples/s]"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "data": {
         "application/vnd.jupyter.widget-view+json": {
          "model_id": "a095fb6168574fe38f9d3268f6b1d1a0",
          "version_major": 2,
          "version_minor": 0
         },
         "text/plain": [
          "Map:   0%|          | 0/200 [00:00<?, ? examples/s]"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "data": {
         "text/plain": [
          "DatasetDict({\n",
          "    train: Dataset({\n",
          "        features: ['title', 'content', 'input_ids', 'attention_mask', 'labels'],\n",
          "        num_rows: 4800\n",
          "    })\n",
          "    test: Dataset({\n",
          "        features: ['title', 'content', 'input_ids', 'attention_mask', 'labels'],\n",
          "        num_rows: 200\n",
          "    })\n",
          "})"
         ]
        },
        "execution_count": 12,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "tokenized_ds = ds.map(process_function, batched=True)\n",
       "tokenized_ds"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
       {
        "data": {
         "text/plain": [
          "'摘要生成: 发布日期:2015-03-3007:55:33郴州市气象台3月30日7时52分发布雷电橙色预警信号:过去2小时北湖区、苏仙区、郴州市区、桂阳县、宜章县、嘉禾县、资兴市、桂东县、汝城县已经受雷电活动影响,并将持续,出现雷电灾害事故的可能性比较大,请注意防范。图例标准防御指南2小时内发生雷电活动的可能性很大,或者已经受雷电活动影响,且可能持续,出现雷电灾害事故的可能性比较大。1、政府及相关部门按照职责落实防雷应急措施;2、人员应当留在室内,并关好门窗;3、户外人员应当躲入有防雷设施的建筑物或者汽车内;4、切断危险电源,不要在树下、电杆下、塔吊下避雨;5、在空旷场地不要打伞,不要把农具、羽毛球拍、高尔夫球杆等扛在肩上。</s>'"
         ]
        },
        "execution_count": 13,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "tokenizer.decode(tokenized_ds[\"train\"][0][\"input_ids\"])"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
       {
        "data": {
         "text/plain": [
          "'郴州市发布雷电橙色预警:过去2小时北湖区、苏仙区、郴州市区、桂阳县、宜章县、嘉禾县、资兴市、桂东县、汝城县已经受...</s>'"
         ]
        },
        "execution_count": 14,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "tokenizer.decode(tokenized_ds[\"train\"][0][\"labels\"])"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Step4 创建模型"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
       {
        "data": {
         "application/vnd.jupyter.widget-view+json": {
          "model_id": "3f941f2771bb4ebeb110da83ac9823ca",
          "version_major": 2,
          "version_minor": 0
         },
         "text/plain": [
          "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ],
      "source": [
       "model = AutoModelForSeq2SeqLM.from_pretrained(\"Langboat/mengzi-t5-base\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Step5 创建评估函数"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
       "import numpy as np\n",
       "from rouge_chinese import Rouge\n",
       "\n",
       "rouge = Rouge()\n",
       "def compute_metric(evalPred):\n",
       "    predictions, labels = evalPred\n",
       "    decode_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
       "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
       "    decode_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
       "\n",
       "    decode_preds = [\" \".join(p) for p in decode_preds]\n",
       "    decode_labels = [\" \".join(l) for l in decode_labels]\n",
       "    scores = rouge.get_scores(decode_preds, decode_labels, avg=True)\n",
       "\n",
       "    return {\n",
       "        \"rouge-1\": scores[\"rouge-1\"][\"f\"],\n",
       "        \"rouge-2\": scores[\"rouge-2\"][\"f\"],\n",
       "        \"rouge-l\": scores[\"rouge-l\"][\"f\"]\n",
       "    }"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Step6 配置训练参数"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
       "import logging\n",
       "\n",
       "logging.basicConfig(level=logging.INFO)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
       {
        "name": "stderr",
        "output_type": "stream",
        "text": [
         "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
         "To disable this warning, you can either:\n",
         "\t- Avoid using `tokenizers` before the fork if possible\n",
         "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
        ]
       }
      ],
      "source": [
       "args = Seq2SeqTrainingArguments(\n",
       "    output_dir=\"./summary-t5\",\n",
       "    per_device_train_batch_size=32,\n",
       "    per_device_eval_batch_size=64,\n",
       "    logging_steps=10,\n",
       "    eval_strategy=\"epoch\",\n",
       "    save_strategy=\"epoch\",\n",
       "    load_best_model_at_end=\"rouge-l\",\n",
       "    predict_with_generate=True\n",
       ")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Step7 创建训练器"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
       "trainer = Seq2SeqTrainer(\n",
       "    args=args,\n",
       "    model=model,\n",
       "    tokenizer=tokenizer,\n",
       "    train_dataset=tokenized_ds[\"train\"],\n",
       "    eval_dataset=tokenized_ds[\"test\"],\n",
       "    compute_metrics=compute_metric,\n",
       "    data_collator=DataCollatorForSeq2Seq(tokenizer)\n",
       ")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Step8 模型训练"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
       {
        "name": "stderr",
        "output_type": "stream",
        "text": [
         "/node6_1/tanshuai/.conda/envs/abc/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
         "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
        ]
       },
       {
        "data": {
         "text/html": [
          "\n",
          "    <div>\n",
          "      \n",
          "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
          "      [150/150 02:53, Epoch 3/3]\n",
          "    </div>\n",
          "    <table border=\"1\" class=\"dataframe\">\n",
          "  <thead>\n",
          " <tr style=\"text-align: left;\">\n",
          "      <th>Epoch</th>\n",
          "      <th>Training Loss</th>\n",
          "      <th>Validation Loss</th>\n",
          "      <th>Rouge-1</th>\n",
          "      <th>Rouge-2</th>\n",
          "      <th>Rouge-l</th>\n",
          "    </tr>\n",
          "  </thead>\n",
          "  <tbody>\n",
          "    <tr>\n",
          "      <td>1</td>\n",
          "      <td>2.303000</td>\n",
          "      <td>2.421367</td>\n",
          "      <td>0.469352</td>\n",
          "      <td>0.299668</td>\n",
          "      <td>0.387081</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <td>2</td>\n",
          "      <td>2.147000</td>\n",
          "      <td>2.350675</td>\n",
          "      <td>0.475941</td>\n",
          "      <td>0.305267</td>\n",
          "      <td>0.392435</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <td>3</td>\n",
          "      <td>2.063300</td>\n",
          "      <td>2.336023</td>\n",
          "      <td>0.481376</td>\n",
          "      <td>0.311972</td>\n",
          "      <td>0.396005</td>\n",
          "    </tr>\n",
          "  </tbody>\n",
          "</table><p>"
         ],
         "text/plain": [
          "<IPython.core.display.HTML object>"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "name": "stderr",
        "output_type": "stream",
        "text": [
         "/node6_1/tanshuai/.conda/envs/abc/lib/python3.9/site-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
         "  warnings.warn(\n",
         "/node6_1/tanshuai/.conda/envs/abc/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
         "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
         "/node6_1/tanshuai/.conda/envs/abc/lib/python3.9/site-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
         "  warnings.warn(\n",
         "/node6_1/tanshuai/.conda/envs/abc/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
         "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
         "/node6_1/tanshuai/.conda/envs/abc/lib/python3.9/site-packages/transformers/generation/utils.py:1249: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
         "  warnings.warn(\n",
         "/node6_1/tanshuai/.conda/envs/abc/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
         "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
         "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n"
        ]
       },
       {
        "data": {
         "text/plain": [
          "TrainOutput(global_step=150, training_loss=2.1627472178141276, metrics={'train_runtime': 177.021, 'train_samples_per_second': 81.346, 'train_steps_per_second': 0.847, 'total_flos': 6775246029127680.0, 'train_loss': 2.1627472178141276, 'epoch': 3.0})"
         ]
        },
        "execution_count": 29,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "trainer.train()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Step9 模型推理"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
       "from transformers import pipeline\n",
       "\n",
       "pipe = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer, device=0)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
       {
        "data": {
         "text/plain": [
          "[{'generated_text': '美国男子同意妻子前往火星的单程之旅,计划的目的是为了开拓人类的居住区,为人类争取更多生存空间。'}]"
         ]
        },
        "execution_count": 38,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "pipe(\"摘要生成：\\n\" + ds[\"test\"][-1][\"content\"], max_length=64, do_sample=True)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
       {
        "data": {
         "text/plain": [
          "'美男子称将把妻子送往火星:预计2026年启程,目标是开拓人类居住地;男子称虽想念妻子但任务意义更大。'"
         ]
        },
        "execution_count": 34,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "ds[\"test\"][-1][\"title\"]"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 2
   }
   