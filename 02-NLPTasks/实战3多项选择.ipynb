{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 多项选择Multiple Choice\n",
       "本质上是分类任务"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Step1 导入相关包"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
       "import evaluate\n",
       "from datasets import load_dataset\n",
       "from transformers import AutoTokenizer, AutoModelForMultipleChoice, TrainingArguments, Trainer"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Step2 加载数据集"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
       {
        "data": {
         "application/vnd.jupyter.widget-view+json": {
          "model_id": "6d12ff920c6849ecbce8e74cd964f95c",
          "version_major": 2,
          "version_minor": 0
         },
         "text/plain": [
          "README.md: 0.00B [00:00, ?B/s]"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "data": {
         "application/vnd.jupyter.widget-view+json": {
          "model_id": "68827cf97ae04b20a81c96f374b90d84",
          "version_major": 2,
          "version_minor": 0
         },
         "text/plain": [
          "test-00000-of-00001.parquet:   0%|          | 0.00/476k [00:00<?, ?B/s]"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "data": {
         "application/vnd.jupyter.widget-view+json": {
          "model_id": "2a1b2faee61b4066809505db531caf4b",
          "version_major": 2,
          "version_minor": 0
         },
         "text/plain": [
          "train-00000-of-00001.parquet:   0%|          | 0.00/3.21M [00:00<?, ?B/s]"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "data": {
         "application/vnd.jupyter.widget-view+json": {
          "model_id": "9f6de46e491849e094c15a799afcf47f",
          "version_major": 2,
          "version_minor": 0
         },
         "text/plain": [
          "validation-00000-of-00001.parquet:   0%|          | 0.00/1.03M [00:00<?, ?B/s]"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "data": {
         "application/vnd.jupyter.widget-view+json": {
          "model_id": "c114a5bd758841fc9866780a630f22ed",
          "version_major": 2,
          "version_minor": 0
         },
         "text/plain": [
          "Generating test split:   0%|          | 0/1625 [00:00<?, ? examples/s]"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "data": {
         "application/vnd.jupyter.widget-view+json": {
          "model_id": "a4a0c20d806a4c81b27da736f9e6ab19",
          "version_major": 2,
          "version_minor": 0
         },
         "text/plain": [
          "Generating train split:   0%|          | 0/11869 [00:00<?, ? examples/s]"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "data": {
         "application/vnd.jupyter.widget-view+json": {
          "model_id": "37c7f5b5cf624151abe30c46c8c3bdcf",
          "version_major": 2,
          "version_minor": 0
         },
         "text/plain": [
          "Generating validation split:   0%|          | 0/3816 [00:00<?, ? examples/s]"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "data": {
         "text/plain": [
          "DatasetDict({\n",
          "    test: Dataset({\n",
          "        features: ['id', 'context', 'question', 'choice', 'answer'],\n",
          "        num_rows: 1625\n",
          "    })\n",
          "    train: Dataset({\n",
          "        features: ['id', 'context', 'question', 'choice', 'answer'],\n",
          "        num_rows: 11869\n",
          "    })\n",
          "    validation: Dataset({\n",
          "        features: ['id', 'context', 'question', 'choice', 'answer'],\n",
          "        num_rows: 3816\n",
          "    })\n",
          "})"
         ]
        },
        "execution_count": 3,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "c3 = load_dataset(\"clue/clue\", \"c3\")\n",
       "c3"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
       {
        "data": {
         "text/plain": [
          "{'id': [0, 1, 2, 3, 4],\n",
          " 'context': [['男：你今天晚上有时间吗?我们一起去看电影吧?', '女：你喜欢恐怖片和爱情片，但是我喜欢喜剧片，科幻片一般。所以……'],\n",
          "  ['男：足球比赛是明天上午八点开始吧?', '女：因为天气不好，比赛改到后天下午三点了。'],\n",
          "  ['女：今天下午的讨论会开得怎么样?', '男：我觉得发言的人太少了。'],\n",
          "  ['男：我记得你以前很爱吃巧克力，最近怎么不吃了，是在减肥吗?', '女：是啊，我希望自己能瘦一点儿。'],\n",
          "  ['女：过几天刘明就要从英国回来了。我还真有点儿想他了，记得那年他是刚过完中秋节走的。',\n",
          "   '男：可不是嘛!自从我去日本留学，就再也没见过他，算一算都五年了。',\n",
          "   '女：从2000年我们在学校第一次见面到现在已经快十年了。我还真想看看刘明变成什么样了!',\n",
          "   '男：你还别说，刘明肯定跟英国绅士一样，也许还能带回来一个英国女朋友呢。']],\n",
          " 'question': ['女的最喜欢哪种电影?',\n",
          "  '根据对话，可以知道什么?',\n",
          "  '关于这次讨论会，我们可以知道什么?',\n",
          "  '女的为什么不吃巧克力了?',\n",
          "  '现在大概是哪一年?'],\n",
          " 'choice': [['恐怖片', '爱情片', '喜剧片', '科幻片'],\n",
          "  ['今天天气不好', '比赛时间变了', '校长忘了时间'],\n",
          "  ['会是昨天开的', '男的没有参加', '讨论得不热烈', '参加的人很少'],\n",
          "  ['刷牙了', '要减肥', '口渴了', '吃饱了'],\n",
          "  ['2005年', '2010年', '2008年', '2009年']],\n",
          " 'answer': ['喜剧片', '比赛时间变了', '讨论得不热烈', '要减肥', '2010年']}"
         ]
        },
        "execution_count": 5,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "c3[\"train\"][:5]"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
       {
        "data": {
         "text/plain": [
          "{'id': [0, 1, 2, 3, 4],\n",
          " 'context': [['老师把一个大玻璃瓶子带到学校，瓶子里装着满满的石头、玻璃碎片和沙子。之后，老师请学生把瓶子里的东西都倒出来，然后再装进去，先从沙子开始。每个学生都试了试，最后都发现没有足够的空间装所有的石头。老师指导学生重新装这个瓶子。这次，先从石头开始，最后再装沙子。石头装进去后，沙子就沉积在石头的周围，最后，所有东西都装进瓶子里了。老师说：“如果我们先从小的东西开始，把小东西装进去之后，大的石头就放不进去了。生活也是如此，如果你的生活先被不重要的事挤满了，那你就无法再装进更大、更重要的事了。”'],\n",
          "  ['老师把一个大玻璃瓶子带到学校，瓶子里装着满满的石头、玻璃碎片和沙子。之后，老师请学生把瓶子里的东西都倒出来，然后再装进去，先从沙子开始。每个学生都试了试，最后都发现没有足够的空间装所有的石头。老师指导学生重新装这个瓶子。这次，先从石头开始，最后再装沙子。石头装进去后，沙子就沉积在石头的周围，最后，所有东西都装进瓶子里了。老师说：“如果我们先从小的东西开始，把小东西装进去之后，大的石头就放不进去了。生活也是如此，如果你的生活先被不重要的事挤满了，那你就无法再装进更大、更重要的事了。”'],\n",
          "  ['老师把一个大玻璃瓶子带到学校，瓶子里装着满满的石头、玻璃碎片和沙子。之后，老师请学生把瓶子里的东西都倒出来，然后再装进去，先从沙子开始。每个学生都试了试，最后都发现没有足够的空间装所有的石头。老师指导学生重新装这个瓶子。这次，先从石头开始，最后再装沙子。石头装进去后，沙子就沉积在石头的周围，最后，所有东西都装进瓶子里了。老师说：“如果我们先从小的东西开始，把小东西装进去之后，大的石头就放不进去了。生活也是如此，如果你的生活先被不重要的事挤满了，那你就无法再装进更大、更重要的事了。”'],\n",
          "  ['这几年公司发展得很不错，每年春节前都会发给工人两个月的奖金，但是今年公司却没挣到多少钱。经理很担心工人们会伤心、失望。这天，他突然想起小时候去买糖：别的服务员都是先抓一大把，拿去称，再一颗一颗减少；只有一个服务员，每次都抓不够重量，然后一颗一颗往上加。虽然拿到的糖是一样的，但人们都喜欢后者。经理想到了办法。过了两天，传来一个消息——今年公司发展不好，有些人可能得离开公司。工人们听了之后都开始担心，以为要离开的是自己。后来经理宣布了一个消息：大家都是一家人，虽然公司有困难，但不能丢掉任何人，只是没有奖金了。这个消息使所有的人都放下了心：奖金不重要，有工作就好。春节快到了，工人们都做了过个穷年的打算。这时经理通知开会，工人们又担心：“会有什么变化吗？”谁知参加会议的人回来兴奋地喊道：“有！有！还是有奖金的！一个月的！”工人们听了，发出一片热烈的欢呼声。'],\n",
          "  ['这几年公司发展得很不错，每年春节前都会发给工人两个月的奖金，但是今年公司却没挣到多少钱。经理很担心工人们会伤心、失望。这天，他突然想起小时候去买糖：别的服务员都是先抓一大把，拿去称，再一颗一颗减少；只有一个服务员，每次都抓不够重量，然后一颗一颗往上加。虽然拿到的糖是一样的，但人们都喜欢后者。经理想到了办法。过了两天，传来一个消息——今年公司发展不好，有些人可能得离开公司。工人们听了之后都开始担心，以为要离开的是自己。后来经理宣布了一个消息：大家都是一家人，虽然公司有困难，但不能丢掉任何人，只是没有奖金了。这个消息使所有的人都放下了心：奖金不重要，有工作就好。春节快到了，工人们都做了过个穷年的打算。这时经理通知开会，工人们又担心：“会有什么变化吗？”谁知参加会议的人回来兴奋地喊道：“有！有！还是有奖金的！一个月的！”工人们听了，发出一片热烈的欢呼声。']],\n",
          " 'question': ['那个任务，学生刚开始完成得怎么样？',\n",
          "  '正确的装法是，先装？',\n",
          "  '上文主要告诉我们，生活中应该？',\n",
          "  '今年公司怎么样？',\n",
          "  '根据经理小时候买糖的情况，可以知道？'],\n",
          " 'choice': [['都没完成', '都装进去了', '完成得很好', '有一组没做完'],\n",
          "  ['小东西', '大东西', '轻的东西', '软的东西'],\n",
          "  ['多思考', '先做小事', '先做重要的事', '多听别人的建议'],\n",
          "  ['发展得不错', '挣的钱不多', '要给工人发糖', '要发两个月的奖金'],\n",
          "  ['服务员给的重量不够', '服务员一块儿一块儿地卖', '服务员卖糖的方式都一样', '不同的卖糖方法影响人的心情']],\n",
          " 'answer': ['', '', '', '', '']}"
         ]
        },
        "execution_count": 6,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "c3[\"test\"][:5]"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
       {
        "data": {
         "text/plain": [
          "Dataset({\n",
          "    features: ['id', 'context', 'question', 'choice', 'answer'],\n",
          "    num_rows: 1625\n",
          "})"
         ]
        },
        "execution_count": 7,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "c3.pop(\"test\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
       {
        "data": {
         "text/plain": [
          "DatasetDict({\n",
          "    train: Dataset({\n",
          "        features: ['id', 'context', 'question', 'choice', 'answer'],\n",
          "        num_rows: 11869\n",
          "    })\n",
          "    validation: Dataset({\n",
          "        features: ['id', 'context', 'question', 'choice', 'answer'],\n",
          "        num_rows: 3816\n",
          "    })\n",
          "})"
         ]
        },
        "execution_count": 8,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "c3"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Step3 数据集预处理"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
       {
        "data": {
         "text/plain": [
          "BertTokenizerFast(name_or_path='hfl/chinese-macbert-base', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
          "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
          "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
          "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
          "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
          "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
          "}"
         ]
        },
        "execution_count": 10,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "tokenizer = AutoTokenizer.from_pretrained(\"hfl/chinese-macbert-base\")\n",
       "tokenizer"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
       "def process_function(examples):\n",
       "    context = []\n",
       "    question_choice = []\n",
       "    labels = []\n",
       "    for idx in range(len(examples[\"context\"])):\n",
       "        ctx = \"\\n\".join(examples[\"context\"][idx])\n",
       "        question = examples[\"question\"][idx]\n",
       "        choices = examples[\"choice\"][idx]\n",
       "        for choice in choices:\n",
       "            context.append(ctx)\n",
       "            question_choice.append(question + \" \" + choice)\n",
       "        if len(choices) < 4:\n",
       "            for _ in range(4 - len(choices)):\n",
       "                context.append(ctx)\n",
       "                question_choice.append(question + \" \" + \"不知道\")\n",
       "        labels.append(choices.index(examples[\"answer\"][idx]))\n",
       "    tokenized_examples = tokenizer(context, question_choice, truncation=\"only_first\", max_length=256, padding=\"max_length\")     # input_ids: 4000 * 256, \n",
       "    tokenized_examples = {k: [v[i: i + 4] for i in range(0, len(v), 4)] for k, v in tokenized_examples.items()}     # 1000 * 4 *256\n",
       "    tokenized_examples[\"labels\"] = labels\n",
       "    return tokenized_examples"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
       {
        "data": {
         "application/vnd.jupyter.widget-view+json": {
          "model_id": "6faafc807f604f9aadb26a05be6f803d",
          "version_major": 2,
          "version_minor": 0
         },
         "text/plain": [
          "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "data": {
         "text/plain": [
          "Dataset({\n",
          "    features: ['id', 'context', 'question', 'choice', 'answer', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
          "    num_rows: 10\n",
          "})"
         ]
        },
        "execution_count": 12,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "res = c3[\"train\"].select(range(10)).map(process_function, batched=True)\n",
       "res"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
       {
        "data": {
         "text/plain": [
          "(10, 4, 256)"
         ]
        },
        "execution_count": 18,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "# res[\"input_ids\"]   # list形式不好看维度\n",
       "import numpy as np\n",
       "np.array(res[\"input_ids\"]).shape"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
       {
        "data": {
         "application/vnd.jupyter.widget-view+json": {
          "model_id": "4362f94b1c8c4b0a85b704299edb835d",
          "version_major": 2,
          "version_minor": 0
         },
         "text/plain": [
          "Map:   0%|          | 0/11869 [00:00<?, ? examples/s]"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "data": {
         "application/vnd.jupyter.widget-view+json": {
          "model_id": "5d58ed13a8774811861fb97edb6ca5a1",
          "version_major": 2,
          "version_minor": 0
         },
         "text/plain": [
          "Map:   0%|          | 0/3816 [00:00<?, ? examples/s]"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "data": {
         "text/plain": [
          "DatasetDict({\n",
          "    train: Dataset({\n",
          "        features: ['id', 'context', 'question', 'choice', 'answer', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
          "        num_rows: 11869\n",
          "    })\n",
          "    validation: Dataset({\n",
          "        features: ['id', 'context', 'question', 'choice', 'answer', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
          "        num_rows: 3816\n",
          "    })\n",
          "})"
         ]
        },
        "execution_count": 19,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "tokenized_c3 = c3.map(process_function, batched=True)\n",
       "tokenized_c3"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Step4 创建模型"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
       {
        "name": "stderr",
        "output_type": "stream",
        "text": [
         "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at hfl/chinese-macbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
         "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
        ]
       }
      ],
      "source": [
       "model = AutoModelForMultipleChoice.from_pretrained(\"hfl/chinese-macbert-base\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Step5 创建评估函数"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
       "import numpy as np\n",
       "\n",
       "accuracy = evaluate.load(\"accuracy\")\n",
       "\n",
       "def compute_metric(pred):  # pred里不是tensor了，是ndarray\n",
       "    predictions, labels = pred\n",
       "    predictions = np.argmax(predictions, axis=-1)\n",
       "    return accuracy.compute(predictions=predictions, references=labels)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Step6 配置训练参数"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
       {
        "name": "stderr",
        "output_type": "stream",
        "text": [
         "/node6_1/tanshuai/.conda/envs/abc/lib/python3.9/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
         "  warnings.warn(\n",
         "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
         "To disable this warning, you can either:\n",
         "\t- Avoid using `tokenizers` before the fork if possible\n",
         "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
         "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
         "To disable this warning, you can either:\n",
         "\t- Avoid using `tokenizers` before the fork if possible\n",
         "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
         "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
         "To disable this warning, you can either:\n",
         "\t- Avoid using `tokenizers` before the fork if possible\n",
         "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
        ]
       }
      ],
      "source": [
       "args = TrainingArguments(\n",
       "    output_dir=\"./multiple_choice\",\n",
       "    per_device_train_batch_size=16,\n",
       "    per_device_eval_batch_size=16,\n",
       "    num_train_epochs=3,\n",
       "    logging_steps=550,\n",
       "    evaluation_strategy=\"epoch\",\n",
       "    save_strategy=\"epoch\",\n",
       "    load_best_model_at_end=True,\n",
       "    fp16=True\n",
       ")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Step7 创建训练器"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
       {
        "name": "stderr",
        "output_type": "stream",
        "text": [
         "/node6_1/tanshuai/.conda/envs/abc/lib/python3.9/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
         "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
        ]
       }
      ],
      "source": [
       "trainer = Trainer(\n",
       "    model=model,\n",
       "    args=args,\n",
       "    train_dataset=tokenized_c3[\"train\"],\n",
       "    eval_dataset=tokenized_c3[\"validation\"],\n",
       "    compute_metrics=compute_metric\n",
       ")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Step8 模型训练"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
       {
        "name": "stderr",
        "output_type": "stream",
        "text": [
         "/node6_1/tanshuai/.conda/envs/abc/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
         "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
        ]
       },
       {
        "data": {
         "text/html": [
          "\n",
          "    <div>\n",
          "      \n",
          "      <progress value='279' max='279' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
          "      [279/279 05:12, Epoch 3/3]\n",
          "    </div>\n",
          "    <table border=\"1\" class=\"dataframe\">\n",
          "  <thead>\n",
          " <tr style=\"text-align: left;\">\n",
          "      <th>Epoch</th>\n",
          "      <th>Training Loss</th>\n",
          "      <th>Validation Loss</th>\n",
          "      <th>Accuracy</th>\n",
          "    </tr>\n",
          "  </thead>\n",
          "  <tbody>\n",
          "    <tr>\n",
          "      <td>1</td>\n",
          "      <td>No log</td>\n",
          "      <td>0.948377</td>\n",
          "      <td>0.589099</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <td>2</td>\n",
          "      <td>No log</td>\n",
          "      <td>0.926713</td>\n",
          "      <td>0.626310</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <td>3</td>\n",
          "      <td>No log</td>\n",
          "      <td>1.013910</td>\n",
          "      <td>0.630503</td>\n",
          "    </tr>\n",
          "  </tbody>\n",
          "</table><p>"
         ],
         "text/plain": [
          "<IPython.core.display.HTML object>"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "name": "stderr",
        "output_type": "stream",
        "text": [
         "/node6_1/tanshuai/.conda/envs/abc/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
         "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
         "/node6_1/tanshuai/.conda/envs/abc/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
         "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
         "/node6_1/tanshuai/.conda/envs/abc/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
         "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
        ]
       },
       {
        "data": {
         "text/plain": [
          "TrainOutput(global_step=279, training_loss=0.8151781635899698, metrics={'train_runtime': 325.9555, 'train_samples_per_second': 109.239, 'train_steps_per_second': 0.856, 'total_flos': 1.873702246273229e+16, 'train_loss': 0.8151781635899698, 'epoch': 3.0})"
         ]
        },
        "execution_count": 25,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "trainer.train()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Step9 模型预测"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
       "import torch\n",
       "\n",
       "# Multiple Choice上没有pipeline进行模型预测\n",
       "class MultipleChoicePipeLine:\n",
       "    def __init__(self, model, tokenizer):\n",
       "        self.model = model\n",
       "        self.tokenizer = tokenizer\n",
       "        self.device = model.device\n",
       "        \n",
       "    def preprocess(self, context, question, choices):\n",
       "        ctx, q_c = [], []\n",
       "        for choice in choices:\n",
       "            ctx.append(context)\n",
       "            q_c.append(question + \" \" + choice)\n",
       "            return tokenizer(ctx, q_c, truncation=\"only_first\", max_length=256, return_tensors=\"pt\")\n",
       "\n",
       "    def predict(self, inputs):\n",
       "        inputs = {k: v.unsqueeze(0).to(self.device) for k, v in inputs.items()}\n",
       "        return self.model(**inputs).logits\n",
       "\n",
       "    def postprocess(self, logits, choices):\n",
       "        prediction = torch.argmax(logits, dim=-1).cpu().item()\n",
       "        return choices[prediction]\n",
       "\n",
       "    def __call__(self, context, question, choices):\n",
       "        inputs = self.preprocess(context, question, choices)\n",
       "        logits = self.predict(inputs)\n",
       "        return self.postprocess(logits, choices)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
       "pipe = MultipleChoicePipeLine(model, tokenizer)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
       {
        "data": {
         "text/plain": [
          "'北京'"
         ]
        },
        "execution_count": 32,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "pipe(\"小明在北京上班\", \"小明在哪里上班？\", [\"北京\", \"上海\", \"河北\", \"海南\", \"河北\", \"海南\"])"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 2
   }
   