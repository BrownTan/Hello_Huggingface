{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Causal-LLM 因果语言模型训练实例"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Step1 导入相关包"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
       "import os\n",
       "\n",
       "# 设置可见的 GPU\n",
       "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4,5,7\"\n",
       "\n",
       "from datasets import load_dataset, Dataset\n",
       "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling, TrainingArguments, Trainer"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Step2 加载数据集"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
       {
        "data": {
         "text/plain": [
          "Dataset({\n",
          "    features: ['completion', 'source'],\n",
          "    num_rows: 10000\n",
          "})"
         ]
        },
        "execution_count": 2,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "ds = load_dataset(\"pleisto/wikipedia-cn-20230720-filtered\", split=\"train[:10000]\")\n",
       "ds"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
       {
        "data": {
         "text/plain": [
          "{'completion': '昭通机场（ZPZT）是位于中国云南昭通的民用机场，始建于1935年，1960年3月开通往返航班“昆明－昭通”，原来属军民合用机场。1986年机场停止使用。1991年11月扩建，于1994年2月恢复通航。是西南地区「文明机场」，通航城市昆明。 机场占地1957亩，飞行区等级为4C，有一条跑道，长2720米，宽48米，可供波音737及以下机型起降。机坪面积6600平方米，停机位2个，航站楼面积1900平方米。位于城东6公里处，民航路与金鹰大道交叉处。\\n航点\\n客服电话\\n昭通机场客服电话：0870-2830004',\n",
          " 'source': 'wikipedia.zh2307'}"
         ]
        },
        "execution_count": 3,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "ds[0]"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Step3 数据集处理"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
       "tokenizer = AutoTokenizer.from_pretrained(\"Langboat/bloom-389m-zh\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
       "def process_function(examples):\n",
       "    # 给每句话加上eos_token，让模型知道什么时候结束\n",
       "    contents = [e + tokenizer.eos_token for e in examples[\"completion\"]]\n",
       "    return tokenizer(contents, truncation=True, max_length=384)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
       {
        "data": {
         "text/plain": [
          "Dataset({\n",
          "    features: ['input_ids', 'attention_mask'],\n",
          "    num_rows: 10000\n",
          "})"
         ]
        },
        "execution_count": 6,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "tokenized_ds = ds.map(process_function, batched=True, remove_columns=ds.column_names)\n",
       "tokenized_ds"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
       {
        "data": {
         "text/plain": [
          "<torch.utils.data.dataloader.DataLoader at 0x7f3288613e20>"
         ]
        },
        "execution_count": 7,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "from torch.utils.data import DataLoader\n",
       "\n",
       "dl = DataLoader(tokenized_ds, batch_size=2, collate_fn=DataCollatorForLanguageModeling(tokenizer, mlm=False))\n",
       "dl"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
       {
        "data": {
         "text/plain": [
          "(0,\n",
          " {'input_ids': tensor([[    3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
          "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
          "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
          "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
          "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
          "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
          "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
          "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
          "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
          "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
          "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
          "              3,     3,     3,     3,     3,     3,     3,     3,     3,     3,\n",
          "              3,     3,     3,     3,     3,     3,     3,     3,  8948,  1262,\n",
          "           9971,   916,    61,    51, 21447,  6496,  5317,  2140, 15952,  8948,\n",
          "          32923, 23296,  9971,   355, 39145, 31097,   355, 11747, 12196,  1359,\n",
          "          18943,  5612, 17102,  1006, 21189,  4571,  8948,  1262,   755,   355,\n",
          "          14122,  3157,  1920,  1157,  1038,   866,  9971,   420, 20446,  9971,\n",
          "           8979,  2436,   420, 11823,  4621, 26650,   355,   937, 11121,  5216,\n",
          "           7442,  1262,  3891,   420,   583, 10051,  3728,  1258, 11358,  9971,\n",
          "           1263,   355,  1262,  3891,  4845, 21189,   420,   210,  9971, 18398,\n",
          "          23055, 15229,   355, 11968,  1473, 14861, 34739,    38,   355, 38274,\n",
          "          24049,   355,  1490,  2057,  1393,  2211,   355,  8124,  2524,  2211,\n",
          "            355, 21761, 23861, 23527,  1107,  4744, 37360,  1491,  3796,   420,\n",
          "           1366, 10937,  6272,  2568,   462, 12640,   355,  3924,  1366,  1389,\n",
          "          14931,   355, 39662,  6272, 18627, 12640,   420,  5317,  2039,  2073,\n",
          "          38097,  1965,   355, 24077,  1599,  1210,  1497, 16633, 13598, 19673,\n",
          "           1965,   671,  3891,  1813,   189, 24793,  7300,   189,  8948,  1262,\n",
          "           9971, 24793,  7300,  1022,  5369,  2259,  1570,  4097, 35933,     2],\n",
          "         [ 3502,  9784,  6663,  1022,  9784,  1028,  6868,   189,  1125,  3502,\n",
          "           9784,  6663, 25767,  3097,  1022,  9784,  1028,  6868,  7093, 19570,\n",
          "           8439,  2332,   230, 15501,   245,  7736, 14573, 20870, 26460, 26136,\n",
          "          14573,  8177,   435,  9644,  8577, 12154,   230, 15501,   245,  7736,\n",
          "          34550,    29, 34209, 17420, 35775,   915, 29982,   937,  8088,  3997,\n",
          "           9488, 15968, 30948, 13490,  6213,   355,  1293,  1490, 13870,  4128,\n",
          "           1807, 28059,   553,  3408,  4048,  3982,  4026, 25434,   355, 19889,\n",
          "           1050,  3571, 16201,   905, 34717,  2910, 12879,  1343, 33703, 16201,\n",
          "           5663,  1125,  3502,  9784,  6663,  1121,   355, 30282,   924,  5663,\n",
          "           2965,   968,  6213,  3097,   671, 31291,   189, 24984,  6213,  5128,\n",
          "           8367,   775,  9245, 34717,  2910, 12879,  1343,  3653,  2759, 16390,\n",
          "           3707,  6398,   355, 32602,  1258, 20345,  6213,  3097, 15384, 35475,\n",
          "          35151,  1125,  3502,  9784,  6663,  5882, 22961,   657,  1263,   671,\n",
          "          26723,  7759,   189,  8037,  3580,   189, 36236,   189,  9198, 35412,\n",
          "          13112,  2332,   101,  7736, 21984, 14229, 21675, 17832,   221,  1263,\n",
          "            189, 28081,  4077,  1022,  2740, 13551,  4128,  1991,   355, 16719,\n",
          "           1022,  3408,  4048,  1058,   124,   891,  4026,   355, 29806,  1022,\n",
          "           4439,  1113,   189,  7455,  8335, 11419,   189,  2280,  1954,  1719,\n",
          "           3406, 10680, 32330, 37259,  3097,   641, 25594,  3097,   355,  1293,\n",
          "          11517,   905, 10443,  1807, 14573,  9497, 14624,  2889,  6554, 12053,\n",
          "            355, 11517,  3097,   937,  8088,  3997,  9488, 12906,   671,   210,\n",
          "          19570,  8439,  2332,   230, 15501,   245,  7736, 14573, 20870, 26460,\n",
          "          26136, 14573,  8177,   435,  9644,  8577, 12154,   230, 15501,   245,\n",
          "           7736, 34550,    29, 34209, 17420, 35775,   189,   210, 19570,  8439,\n",
          "           2332,   230, 15501,   245,  7736, 14573, 20870, 26460, 26136, 14573,\n",
          "           3287, 19858,  3287, 30866,  8577,  3287,  2332,   230, 15501,   245,\n",
          "           7736, 34550,   718, 12154,   106, 13112, 17420, 35775,  3287, 28745,\n",
          "          35940, 34209, 34550,  3287, 16534, 12319,  6434, 25594,  3097,     2]]), 'attention_mask': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
          "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
          "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
          "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
          "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
          "          0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
          "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
          "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
          "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
          "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
          "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
          "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
          "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
          "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
          "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
          "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
          "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
          "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
          "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
          "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
          "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
          "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
          "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
          "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[ -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
          "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
          "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
          "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
          "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
          "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
          "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
          "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
          "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
          "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
          "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
          "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
          "           -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  8948,  1262,\n",
          "           9971,   916,    61,    51, 21447,  6496,  5317,  2140, 15952,  8948,\n",
          "          32923, 23296,  9971,   355, 39145, 31097,   355, 11747, 12196,  1359,\n",
          "          18943,  5612, 17102,  1006, 21189,  4571,  8948,  1262,   755,   355,\n",
          "          14122,  3157,  1920,  1157,  1038,   866,  9971,   420, 20446,  9971,\n",
          "           8979,  2436,   420, 11823,  4621, 26650,   355,   937, 11121,  5216,\n",
          "           7442,  1262,  3891,   420,   583, 10051,  3728,  1258, 11358,  9971,\n",
          "           1263,   355,  1262,  3891,  4845, 21189,   420,   210,  9971, 18398,\n",
          "          23055, 15229,   355, 11968,  1473, 14861, 34739,    38,   355, 38274,\n",
          "          24049,   355,  1490,  2057,  1393,  2211,   355,  8124,  2524,  2211,\n",
          "            355, 21761, 23861, 23527,  1107,  4744, 37360,  1491,  3796,   420,\n",
          "           1366, 10937,  6272,  2568,   462, 12640,   355,  3924,  1366,  1389,\n",
          "          14931,   355, 39662,  6272, 18627, 12640,   420,  5317,  2039,  2073,\n",
          "          38097,  1965,   355, 24077,  1599,  1210,  1497, 16633, 13598, 19673,\n",
          "           1965,   671,  3891,  1813,   189, 24793,  7300,   189,  8948,  1262,\n",
          "           9971, 24793,  7300,  1022,  5369,  2259,  1570,  4097, 35933,     2],\n",
          "         [ 3502,  9784,  6663,  1022,  9784,  1028,  6868,   189,  1125,  3502,\n",
          "           9784,  6663, 25767,  3097,  1022,  9784,  1028,  6868,  7093, 19570,\n",
          "           8439,  2332,   230, 15501,   245,  7736, 14573, 20870, 26460, 26136,\n",
          "          14573,  8177,   435,  9644,  8577, 12154,   230, 15501,   245,  7736,\n",
          "          34550,    29, 34209, 17420, 35775,   915, 29982,   937,  8088,  3997,\n",
          "           9488, 15968, 30948, 13490,  6213,   355,  1293,  1490, 13870,  4128,\n",
          "           1807, 28059,   553,  3408,  4048,  3982,  4026, 25434,   355, 19889,\n",
          "           1050,  3571, 16201,   905, 34717,  2910, 12879,  1343, 33703, 16201,\n",
          "           5663,  1125,  3502,  9784,  6663,  1121,   355, 30282,   924,  5663,\n",
          "           2965,   968,  6213,  3097,   671, 31291,   189, 24984,  6213,  5128,\n",
          "           8367,   775,  9245, 34717,  2910, 12879,  1343,  3653,  2759, 16390,\n",
          "           3707,  6398,   355, 32602,  1258, 20345,  6213,  3097, 15384, 35475,\n",
          "          35151,  1125,  3502,  9784,  6663,  5882, 22961,   657,  1263,   671,\n",
          "          26723,  7759,   189,  8037,  3580,   189, 36236,   189,  9198, 35412,\n",
          "          13112,  2332,   101,  7736, 21984, 14229, 21675, 17832,   221,  1263,\n",
          "            189, 28081,  4077,  1022,  2740, 13551,  4128,  1991,   355, 16719,\n",
          "           1022,  3408,  4048,  1058,   124,   891,  4026,   355, 29806,  1022,\n",
          "           4439,  1113,   189,  7455,  8335, 11419,   189,  2280,  1954,  1719,\n",
          "           3406, 10680, 32330, 37259,  3097,   641, 25594,  3097,   355,  1293,\n",
          "          11517,   905, 10443,  1807, 14573,  9497, 14624,  2889,  6554, 12053,\n",
          "            355, 11517,  3097,   937,  8088,  3997,  9488, 12906,   671,   210,\n",
          "          19570,  8439,  2332,   230, 15501,   245,  7736, 14573, 20870, 26460,\n",
          "          26136, 14573,  8177,   435,  9644,  8577, 12154,   230, 15501,   245,\n",
          "           7736, 34550,    29, 34209, 17420, 35775,   189,   210, 19570,  8439,\n",
          "           2332,   230, 15501,   245,  7736, 14573, 20870, 26460, 26136, 14573,\n",
          "           3287, 19858,  3287, 30866,  8577,  3287,  2332,   230, 15501,   245,\n",
          "           7736, 34550,   718, 12154,   106, 13112, 17420, 35775,  3287, 28745,\n",
          "          35940, 34209, 34550,  3287, 16534, 12319,  6434, 25594,  3097,     2]])})"
         ]
        },
        "execution_count": 8,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "next(enumerate(dl))  # attention_mask中的非-100值代表被mask的token，即input_ids里的103"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
       {
        "data": {
         "text/plain": [
          "('<pad>', 3)"
         ]
        },
        "execution_count": 9,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "tokenizer.pad_token, tokenizer.pad_token_id"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
       {
        "data": {
         "text/plain": [
          "('</s>', 2)"
         ]
        },
        "execution_count": 11,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "tokenizer.eos_token, tokenizer.eos_token_id"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Step4 创建模型"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
       {
        "data": {
         "application/vnd.jupyter.widget-view+json": {
          "model_id": "054b02fb911d4627bf7332496fd3569d",
          "version_major": 2,
          "version_minor": 0
         },
         "text/plain": [
          "config.json:   0%|          | 0.00/431 [00:00<?, ?B/s]"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "data": {
         "application/vnd.jupyter.widget-view+json": {
          "model_id": "887e62e4bce24dfd8d6a9ec3b138292f",
          "version_major": 2,
          "version_minor": 0
         },
         "text/plain": [
          "pytorch_model.bin:   0%|          | 0.00/1.56G [00:00<?, ?B/s]"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ],
      "source": [
       "model = AutoModelForCausalLM.from_pretrained(\"Langboat/bloom-389m-zh\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Step5 配置训练参数"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
       "import logging\n",
       "\n",
       "logging.basicConfig(level=logging.INFO)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
       "args = TrainingArguments(\n",
       "    output_dir=\"./causal_lm\",\n",
       "    per_device_train_batch_size=32,\n",
       "    logging_steps=10,\n",
       "    num_train_epochs=1\n",
       ")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Step6 创建训练器"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
       "trainer = Trainer(\n",
       "    args=args,\n",
       "    model=model,\n",
       "    tokenizer=tokenizer,\n",
       "    train_dataset=tokenized_ds,\n",
       "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
       ")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Step7 模型训练"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
       {
        "name": "stderr",
        "output_type": "stream",
        "text": [
         "/node6_1/tanshuai/.conda/envs/abc/lib/python3.9/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
         "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
        ]
       },
       {
        "data": {
         "text/html": [
          "\n",
          "    <div>\n",
          "      \n",
          "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
          "      [105/105 03:47, Epoch 1/1]\n",
          "    </div>\n",
          "    <table border=\"1\" class=\"dataframe\">\n",
          "  <thead>\n",
          " <tr style=\"text-align: left;\">\n",
          "      <th>Step</th>\n",
          "      <th>Training Loss</th>\n",
          "    </tr>\n",
          "  </thead>\n",
          "  <tbody>\n",
          "    <tr>\n",
          "      <td>10</td>\n",
          "      <td>3.928700</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <td>20</td>\n",
          "      <td>3.744900</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <td>30</td>\n",
          "      <td>3.600500</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <td>40</td>\n",
          "      <td>3.636900</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <td>50</td>\n",
          "      <td>3.598600</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <td>60</td>\n",
          "      <td>3.524000</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <td>70</td>\n",
          "      <td>3.533900</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <td>80</td>\n",
          "      <td>3.455900</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <td>90</td>\n",
          "      <td>3.486100</td>\n",
          "    </tr>\n",
          "    <tr>\n",
          "      <td>100</td>\n",
          "      <td>3.506600</td>\n",
          "    </tr>\n",
          "  </tbody>\n",
          "</table><p>"
         ],
         "text/plain": [
          "<IPython.core.display.HTML object>"
         ]
        },
        "metadata": {},
        "output_type": "display_data"
       },
       {
        "data": {
         "text/plain": [
          "TrainOutput(global_step=105, training_loss=3.595743124825614, metrics={'train_runtime': 233.7499, 'train_samples_per_second': 42.781, 'train_steps_per_second': 0.449, 'total_flos': 6965302394880000.0, 'train_loss': 3.595743124825614, 'epoch': 1.0})"
         ]
        },
        "execution_count": 17,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "trainer.train()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### Step8 模型推理"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
       "from transformers import pipeline\n",
       "\n",
       "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
       {
        "data": {
         "text/plain": [
          "[{'generated_text': '昭通机场（ZPZT）是位于中国云南昭通的民用机场，始建于1958年，1987年随昭北机场建成通飞机起降，2000年机场改建为货运机场，2003年机场改建为民用机场，2008年机场扩建改造工程进入尾声。\\n航线\\n咸阳站是咸阳市的枢纽航空航点，也是咸阳主城区的集交会点，机场分属咸阳主城区的咸阳经济开发区、咸阳客运枢纽机场。\\n其他机场\\n* 咸阳经济开发区\\n* 咸阳客运枢纽机场\\n* 咸阳经济技术开发区机场\\n* 咸阳'}]"
         ]
        },
        "execution_count": 23,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "pipe(\"昭通机场（ZPZT）是位于中国云南昭通的民用\", max_length=128, do_sample=True)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
       {
        "name": "stderr",
        "output_type": "stream",
        "text": [
         "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
        ]
       },
       {
        "data": {
         "text/plain": [
          "[{'generated_text': '结构化剪枝是一种深度学习模型压缩机制，能够产生许多剪枝并保持剪枝的深度一致。深度学习是一种基于特征学习的深度融合函数，特征就是用于识别并识别对象的可识别值。\\n深度学习模型可以产生多个剪枝，而当参数向量得到足够多的时候，剪枝的数量就会比原来的数少，因此，深度学习模型可以压缩图像，减少剪枝，并提高图像的质量。\\n生成化剪枝\\n生成化剪枝是图像序列（图像序列是剪枝数量，而不是剪枝大小）的一部份，生成化剪枝可以作为图像特征值'}]"
         ]
        },
        "execution_count": 29,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "pipe(\"结构化剪枝是一种深度学习模型压缩\", max_length=128, do_sample=True)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
       {
        "data": {
         "text/plain": [
          "[{'generated_text': '下面是一则游戏新闻。小编报道，近日，游戏产业发展的非常好的地方——日本任天堂推出了一款基于掌机掌阅智能系统PlayStation 3的智能手机游戏——Pokemon Go，并宣称该款游戏可以玩到《Pokemon》这个系列的全部游戏了。\\n游戏制作\\n日本任天堂和松下公司合作开发了与掌阅智能系统PlayStation 3的智能手机游戏，不过任天堂方面对游戏内容的宣传并没有披露相关内容。Pokemon Go由任天堂和松下公司联手开发的。任天堂向《Pokemon Go》开发的团队，如Pokemon Go的开发人员——Kazaki'}]"
         ]
        },
        "execution_count": 30,
        "metadata": {},
        "output_type": "execute_result"
       }
      ],
      "source": [
       "pipe(\"下面是一则游戏新闻。小编报道，近日，游戏产业发展的非常\", max_length=128, do_sample=True)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 2
   }
   